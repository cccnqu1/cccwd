<html>
<head>
  <meta charset="utf-8" />
</head>
<body>
<script src="../../gospa.js"></script>
<title> 陳鍾誠  / 教科書  / 人工智慧 / 最大概似估計</title>

 [[陳鍾誠]](ccc:home)  / [[教科書]](book:home)  / [[人工智慧]](ai:home) 

<h2 id="">最大概似估計</h2>

<h3 id="">簡介</h3>

<ul>
<li>機率密度函數：$f(X|\theta)$, $\theta$ 為未知。</li>
<li>概似函數：$L(\theta) = \prod_{i=1}^n f(x_i)$</li>
<li>求可以讓 $L(\theta)$ 最大化的 $\theta$ 參數 $\hat{\theta}$。
<ul><li>可以直接最大化 $L(\theta)$ ，或者最大化 $ln L(\theta)$ 亦可 </li>
<li>(因為許多獨立隨機變數的算式會表現為某些機率式的乘積，此時取 ln 可以讓這些乘積轉化為相加的運算，數學上會變得較為簡單)。</li></ul></li>
<li>用 $\hat{\theta}$ 取代 $\theta$ ，就可得到最大慨似估計式。</li>
<li>利用已知樣本求取「最大慨似估計式」的觀察值，以便估計其中的參數值。</li>
</ul>

<p>說明：如果是常態分布，通常 $\theta = (\mu, \delta^2)$</p>

<p>對於任何一個隨機現象，我們可以用隨機變數 $X$ 描述，假設樣本 x 的機率分布以 $p(x)$ 表示。</p>

<p>假如經過觀察之後，經由觀察數據 $x_1,x_2,.....,x_n$ 的統計，得到其分布為 $p'(x)$ ，於是我們就可以利用機率分布 $p'$ 反推出 $p$。</p>

<p>一個最簡單的想法是 $p(x) = p'(x)$，也就是這些觀察是具有代表性的，於是統計上的機率分布符合真實的機率分佈。</p>

<p>這個想法的背後，其實是有理論基礎的，其理論稱為「最大似然法則」或「最大概似估計」 (Maximum Likelihood Estimation)。</p>

<h3 id="">最大概似估計的數學想法</h3>

<p>隨然我們觀察到的統計現象是 p'，但是真正的 p 卻有無限多種可能，基本上任何機率分布都可能產生觀察現象 p'。</p>

<p>即便如此，每一個機率分布 p 會產生觀察現象 p' 的可能性卻大有不同，假如機率模型 p 與 p'(x) 的分布一致 ，那麼 p 產生 p'(x) 現象的機率將會是最大的。</p>

<p>因此，設定 $p(x) = p'(x)$ 的想法，其背後的目標乃是要最大化機率源模型 p 產生 p' 現象的可能性，這個最大化的目標就稱為「最大概似估計」。</p>

<h3 id="">一個簡單的範例</h3>

<p>假如我們觀察拋擲銅板的現象，得到觀察序列 x = {0, 1, 0, 0, 1, 1, 0, 0, 0, 1 } 這個現象，其中的 1 代表正面 (人頭)，0 代表反面 (字)，因此正面共出現 4 次，反面共出現 6 次。</p>

<p>因此，$p'(1) = 0.4, p'(0) = 0.6$。</p>

<p>那麼我們應該如何假設 p(0) 與 p(1) 的機率分布呢？</p>

<p>根據最大似然法則，我們應該去找出一個機率模型 p 可以最大化下列算式。</p>

<p>$\arg\max_p \; p(x) = \arg\max \prod_i p(x_i)$</p>

<p>我們可以計算看看下列兩個機率模型 p1, p2, p3 可能產生 x 的機率各為多少。</p>

<p>$\begin{array} p1(1)=0.5 ; p1(0) = 0.5 \\ p2(1)=0.2 ; p2(0) = 0.8 \\ p3(1)=0.4 ; p3(0) = 0.6\end{array}$</p>

<p>根據簡單的機率公式，我們可以算出下列結果。</p>

<p>$\begin{array} p1(x) = \prod_i p1(x_i) = 0.5^4 \cdot 0.5^6 = 0.00097656 \\ p2(x) = \prod_i p2(x_i) = 0.2^4 \cdot 0.8^6 = 0.00041943 \\ p3(x) = \prod_i p3(x_i) = 0.4^4 \cdot 0.6^6 = 0.00119439\end{array}$</p>

<p>因此果然驗證了最可能的機率模型是 p3，也就是 p(1)=0.4, p(0)=0.6。</p>

<p>雖然我們找出了符合觀察現象 x 的最可能機率模型 (p3) ，但是對於投擲銅板這件事而言，p3 卻不是最適當的模型，因為最適當的模型是 p1 。</p>

<p>這個例子說明了一件事實，用最大似然法則所找出來的機率模型 p'  未必是真正的機率源模型，只是根據觀察現象 x 所推導出來的最佳化機率模型而已。</p>

<p>但是，假如統計資料 x 序列的長度更長，那麼 x 的統計數據通常會更接近真實機率分布 X，因此最大似然法則所找出的機率模型 p' 也就會更接近機率源模型 p，於是我們就可以認為 p' 足以代表 p 了。</p>

<h3 id="">銅板問題的最大概似估計</h3>

<p>EM 演算法是一種「最大概似估計」 (Maximum Likelihood Estimation, MLE)，要瞭解 EM 演算法之前，先讓我們瞭解何謂「最大概似估計」。</p>

<p>假如連續投擲一個銅板，結果有 H 次正面，T 次反面，那麼假設該銅板的正面機率為 $\theta$ ，那麼請問甚麼樣的 $\theta$ 會讓這個 (H, T) 結果的機率最大呢？</p>

<p>對於正面機率 $\theta$ 的銅板，我們可以用二項分布計算出現 #T 次正面 #H 次反面的機率為 $C(H+T, H) \cdot \theta^H (1-\theta)^T$ 。</p>

<p>由於其中的 C(H+T, H) 與 $\theta$ 無關，因此我們只需要最大化後面那一項，也就是 $\arg\max_{\theta} \theta^H (1-\theta)^T$ 。</p>

<p>此時若我們先取 log，則最大值的 $\theta$ 點並不會改變，因此我們可以改為 $\arg\max_{\theta}\;H \log(\theta)+T\log(1-\theta)$ </p>

<p>到底甚麼樣的 $\theta$ 值會讓上述算式最大呢？我們可以對上式取微分，尋找斜率為零的點。</p>

<blockquote>
  <p>$\frac{d}{d\theta} (H \log(\theta)+T\log(1-\theta)) = \frac{H}{\theta}+\frac{T}{1-\theta} = 0$ ; 連續可微函數最大值的斜率等於零。</p>
  
  <p>=> $(1-\theta) H = T \theta$  ; 移項可得</p>
  
  <p>=> $H=\theta (T+H)$ ; 將 $\theta$ 放到同一邊</p>
  
  <p>=> $\theta = \frac{H}{T+H}$ ; 求得解答，最大化該式的 $\theta$ 為 $\frac{H}{T+H}$</p>
</blockquote>

<p>因此，我們可以知道最大化 $\arg\max_{\theta}\;\theta^H (1-\theta)^T$ 這個算式的 $\theta$ 為 $\frac{H}{T+H}$ ，而這個 $\theta$ 也正是該問題的最大概似估計。</p>

<h3 id="">最大條件機率的分布</h3>

<p>針對許多機率現象，我們只能觀察到某些面向的結果，但是無法觀察到全部的面向。這種情況就可以使用條件機率。</p>

<p>根據最大似然法則，假如已觀察到聯合機率分布 (X,Y)，其中 (x,y) 事件出現的機率為 p'(x,y) ，那麼根據最大似然法則，我們應當尋求盡可能滿足下列條件的算式。</p>

<p>$\arg\max_h \; P(x,y|h)$</p>

<p>然而，通常雙變數的聯合機率分布 p'(x,y) 會遭遇到『樣本稀疏性』的問題，因此若直接最大化上述算式，將會造成相當大的統計偏差。</p>

<p>為了解決『樣本稀疏性』的問題，我們應該採用較為可信的 p'(x) 作為 p(x) 的估計，p'(y) 作為 p(y) 的估計，而非直接採用 p'(x,y) 作為 p(x,y) 的估計值。</p>

<p>$\begin{array} p'(x,y) &amp;=&amp; \frac{p'(x,y)}{p'(x) p'(y)} \cdot p'(x) p'(y) \\&amp; \sim &amp;  \frac{p(x,y)}{p'(x) p'(y)} \cdot p'(x) p'(y)\end{array}$</p>

<p>於是我們可以最佳化下列算式</p>

<p>$\arg\max_p \; \frac{p(x,y)}{p'(x) p'(y)} \cdot p'(x) p'(y)$</p>

<p>根據條件機率的定義，我們可以將 p'(x,y) 改寫如下。</p>

<p>$p'(x,y) = p'(x)\cdotp'(y|x)$</p>

<p>如果我們用 p(y|x) 取代 p'(y|x)，那麼我們應該最大化下列算式。</p>

<p>於是我們可以最大化下列算式。</p>

<p>$\arg\max \; { p'(x) \cdot p(y|x) }$</p>

<p>針對機率分布 p 而言，其機率為 p(x,y) 相當於下列算式。</p>

<p>$arg\max \; p(X',Y') = \arg\max \; \prod_{x',y'} p(x',y') =  \arg\max \; \prod_{x',y'} p(x') p(y'|x')$</p>

<p>根據微積分的原理，如果我們對上述算式進行微分的動作，那麼最佳解將會式微分式為 0 的 p 解 。</p>

</body>
</html>